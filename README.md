# FinRisk Copilot ‚Äî End‚Äëto‚ÄëEnd Banking AI (LoRA/PEFT + RAG + MLOps)

**Elevator pitch:** A production‚Äëstyle system that detects suspicious transactions (tabular ML),
generates bank‚Äëtone explanations using a **LoRA‚Äëfine‚Äëtuned** LLM, and answers policy questions via **RAG**.
Everything is tracked with MLflow, served via FastAPI, dockerized, and wired with CI + monitoring.

> Designed to show **senior‚Äëlevel ownership** across DS, LLMs (PEFT), and MLOps for a bank context.

---

## Architecture (three components)

- **A) Fraud Detector (Tabular ML)** ‚Äî LightGBM/XGBoost, class imbalance handling, calibration, SHAP.
- **B) Reason‚ÄëCode Explainer (LLM + LoRA/QLoRA)** ‚Äî PEFT adapters to write short regulator‚Äëstyle narratives.
- **C) Policy/Risk Assistant (RAG)** ‚Äî PDF ingestion ‚Üí embeddings ‚Üí vector index ‚Üí grounded answers with citations.

Glue: MLflow tracking/registry, FastAPI service, Docker, GitHub Actions, Evidently monitoring.

```
Data ‚Üí Features ‚Üí Train (tabular) ‚Üí PR‚ÄëAUC/Threshold ‚Üí SHAP
           ‚Üò signals ‚Üí LoRA (LLM) ‚Üí case narration
Docs/PDFs ‚Üí chunk/embed ‚Üí vector store ‚Üí RAG answers
All artifacts tracked in MLflow ‚Üí served via FastAPI ‚Üí monitored
```

---

## Quickstart (Milestone 1 ‚Äî Repo & Environment)

> **Python version:** 3.11 recommended (widest library compatibility).

1. **Create virtual environment**
   ```bash
   python3.11 -m venv .venv           # ensure Python 3.11 installed
   source .venv/bin/activate          # Windows: .venv\Scripts\activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

2. **Run the API locally (smoke test)**
   ```bash
   uvicorn src.service.app:app --reload --port 8000
   # open http://127.0.0.1:8000/health ‚Üí {"status":"ok"}
   ```

3. **Run tests**
   ```bash
   pytest -q
   ```

4. **Pre‚Äëcommit hooks (format & lint on commit)**
   ```bash
   pre-commit install
   ```

5. **Git & GitHub (first push)**
   ```bash
   git init
   git branch -M main
   git add .
   git commit -m "init: scaffold repo, README, CI, FastAPI smoke test"
   git remote add origin <YOUR_GITHUB_REPO_URL>
   git push -u origin main
   ```

> **Mac with Apple Silicon (M‚Äëseries):** Some packages (e.g., FAISS, bitsandbytes) are optional and platform‚Äëspecific. 
> Start with the current `requirements.txt`. We‚Äôll add GPU‚Äëonly extras later from a Linux/CUDA machine or Colab.

---

## Project Structure

```
finrisk-copilot/
‚îú‚îÄ README.md
‚îú‚îÄ requirements.txt
‚îú‚îÄ .pre-commit-config.yaml
‚îú‚îÄ .gitignore
‚îú‚îÄ LICENSE
‚îú‚îÄ .github/workflows/ci.yml
‚îú‚îÄ docker/Dockerfile
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ service/app.py            # FastAPI health check + placeholder endpoints
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ config/__init__.py
‚îÇ  ‚îú‚îÄ data/__init__.py
‚îÇ  ‚îú‚îÄ models/__init__.py
‚îÇ  ‚îú‚îÄ rag/__init__.py
‚îÇ  ‚îú‚îÄ utils/__init__.py
‚îú‚îÄ data/                        # (ignored) raw/interim/processed go here
‚îÇ  ‚îú‚îÄ .gitignore
‚îÇ  ‚îú‚îÄ raw/.gitkeep
‚îÇ  ‚îú‚îÄ interim/.gitkeep
‚îÇ  ‚îî‚îÄ processed/.gitkeep
‚îî‚îÄ tests/
   ‚îú‚îÄ test_api.py
   ‚îî‚îÄ __init__.py
```

## üß† Fine-Tuning LLM for Credit Risk Explanations

This notebook, `llama_finetune.ipynb`, demonstrates how I fine-tuned **TinyLlama**, a lightweight open LLM, on a dataset of German Credit Risk profiles. The goal is to make the model generate **interpretable explanations** for credit approval or denial decisions.

### ‚öôÔ∏è What it does
- Uses **Hugging Face Transformers**, **PEFT**, and **LoRA** for parameter-efficient fine-tuning.
- Quantized the model to 8-bit using `bitsandbytes` to fit within Colab GPU memory.
- Fine-tuned on `german_credit_explanations.jsonl`, a dataset containing financial attributes and human-readable risk explanations.
- The final model (`tinyllama-credit-explainer`) is uploaded to my [Hugging Face Hub](https://huggingface.co/rohankatyayani/tinyllama-credit-explainer).

### üß© Tech Stack
- **Model:** TinyLlama-1.1B
- **Libraries:** Hugging Face Transformers, Datasets, PEFT (LoRA), BitsAndBytes
- **Notebook:** Google Colab (with CUDA)
- **Repo:** [finrisk-copilot](https://github.com/RohanKatyayani/finrisk-copilot)
- **Goal:** Explain model decisions in financial risk applications ‚Äî improving transparency and trust in AI-driven lending.

---

üí¨ *Next step:* Integrate this fine-tuned model into the FinRisk Copilot pipeline for explainable credit assessments.

---

## Roadmap (you‚Äôll tick these off)

- [x] **Milestone 1:** Repo ready, env & CI pass, API health OK
- [x] **Milestone 2:** Tabular fraud dataset prepared (train/valid split), baseline LightGBM with PR‚ÄëAUC
- [x] **Milestone 3:** SHAP explanations + threshold tuning + calibration
- [x] **Milestone 4:** Synthetic ‚Äúreason‚Äëcode‚Äù dataset generation
- [x] **Milestone 5:** LoRA/QLoRA training (GPU/Colab) + eval
- [ ] **Milestone 6:** RAG over policy PDFs + citations
- [ ] **Milestone 7:** Unified FastAPI service endpoints
- [ ] **Milestone 8:** Docker + GitHub Actions CI
- [ ] **Milestone 9:** Monitoring (Evidently) + model/data cards
- [ ] **Milestone 10:** Demo script + interview notes

---

## Interview soundbite for this milestone

> ‚ÄúI started by pinning Python 3.11, setting up a clean repo with pre‚Äëcommit (black/ruff), CI on PRs, and a FastAPI health endpoint. 
> This gives me reproducibility and guardrails before I add heavy ML/LLM pieces.‚Äù

---

## License

MIT ¬© 2025 Rohan Katyayani
